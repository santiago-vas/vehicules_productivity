{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px;font-weight:bold;margin-bottom:10px;'> Boilerplate - Looker Projects </h1> <br>\n",
    "<p style='font-size:20px;'> codigo generico para tableros de PRODUCTIVIDAD DE FLOTA</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from datetime import timedelta, time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import math\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from functions.genericFunctions import *\n",
    "from functions.functionEncription import *\n",
    "urlConnections = '../../settings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_diff(list1, list2):\n",
    "    out = [item for item in list1 if not item in list2]\n",
    "    return out\n",
    "\n",
    "def getLastData(imeisToAnalyze,project,clientId,nameDate,tableName):\n",
    "    # Last date\n",
    "    try:  \n",
    "        deviceList = pd.read_sql(\"\"\"select imei, max(max_date) as begin_time from p_confd \n",
    "                where type='channel_daily' and flat=1 and process_name='{}' and client_id={} and dashboard_type='{}'\n",
    "                group by imei \"\"\".format(processName, clientId, dashboardType), psqlCon)\n",
    "        print('postgres ', deviceList.shape)\n",
    "        if len(deviceList)==0: \n",
    "            \n",
    "            queryLastDate = clientBigQueryLookerAnalytics.query(\"\"\"SELECT imei, max({}) as begin_time\n",
    "                                              FROM `{}.{}.{}`\n",
    "                                              where clientId='{}'\n",
    "                                              GROUP BY imei\"\"\")\n",
    "            resultLastDate = queryLastDate.result()\n",
    "            deviceList = resultLastDate.to_dataframe()\n",
    "            print('looker ', deviceList.shape)\n",
    "            \n",
    "        else: pass\n",
    "        deviceList['begin_time'] = pd.to_datetime(deviceList.begin_time).dt.tz_localize(None)\n",
    "        \n",
    "    except: \n",
    "        deviceList = pd.DataFrame(columns={'imei', 'begin_time'})            \n",
    "\n",
    "    totalImeiList = imeisToAnalyze.imei.unique().tolist()\n",
    "    currentDeviceList = deviceList.imei.unique().tolist()\n",
    "    imeiDiff = list_diff(totalImeiList, currentDeviceList)\n",
    "    \n",
    "    dateToProcess = datetime.utcnow() + timedelta(days = -5)  \n",
    "    startDate = datetime.combine(dateToProcess, time.min)\n",
    "    endDate = datetime.combine(datetime.utcnow(), time.min) \n",
    "    deviceList['end_time'] = endDate\n",
    "    for imei in imeiDiff:\n",
    "        plate = pd.DataFrame({\n",
    "        'imei': imei,\n",
    "        'begin_time': startDate,\n",
    "        'end_time': endDate,\n",
    "        }, index = { 'indice': 0 })\n",
    "        deviceList = deviceList.append(plate)\n",
    " \n",
    "    deviceList['end_time'] = deviceList['end_time'].apply(lambda x: x.replace(microsecond = 0))\n",
    "    deviceList.reset_index(drop=True, inplace=True)\n",
    "    return (deviceList)\n",
    "\n",
    "def saveData(finalDataFrame,clientId,env,whatToDo,tableName,credenciales):\n",
    "    if len(finalDataFrame.index) > 0:\n",
    "        finalDataFrame.to_gbq(destination_table = \"{}.{}\".format(clientId,tableName), \n",
    "                project_id = env, credentials = credenciales, if_exists = whatToDo)\n",
    "    else:\n",
    "        print(\"No hay data, no se guarda nada\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idleTime(data):\n",
    "    ignition=1\n",
    "    timeSpeed = 0\n",
    "    minSpeed=2\n",
    "    event = 0\n",
    "    data= data.reset_index(drop=True)\n",
    "    previousRow = data.index[0]\n",
    "    \n",
    "    for row in data.index[range(1, data.shape[0])]:   \n",
    "        speed = data.at[row, \"speed\"]\n",
    "        generateTime = data.at[row, \"generateTime\"] \n",
    "        generateTimePrevious = data.at[previousRow,\"generateTime\"] \n",
    "        ignitionState = data.at[previousRow,\"ignitionState\"] \n",
    "        \n",
    "        try:\n",
    "            if math.isnan(speed) == True:\n",
    "                speed = 0\n",
    "            if (speed < minSpeed) & (ignitionState==ignition):\n",
    "                timeSpeed = timeSpeed + (generateTime - generateTimePrevious).seconds\n",
    "                event = event + 1\n",
    "            previousRow = row\n",
    "        except Exception as ex:\n",
    "            continue\n",
    "\n",
    "    return(timeSpeed)\n",
    "\n",
    "def movementTime(data):\n",
    "    ignition=1\n",
    "    timeSpeed = 0\n",
    "    minSpeed=2\n",
    "    event = 0\n",
    "    data= data.reset_index(drop=True)\n",
    "    previousRow = data.index[0]\n",
    "    \n",
    "    for row in data.index[range(1, data.shape[0])]:   \n",
    "        speed = data.at[row, \"speed\"]\n",
    "        generateTime = data.at[row, \"generateTime\"] \n",
    "        generateTimePrevious = data.at[previousRow,\"generateTime\"] \n",
    "        ignitionState = data.at[previousRow,\"ignitionState\"] \n",
    "        \n",
    "        try:\n",
    "            if math.isnan(speed) == True:\n",
    "                speed = 0\n",
    "            if (speed >= minSpeed) & (ignitionState==ignition):\n",
    "                timeSpeed = timeSpeed + (generateTime - generateTimePrevious).seconds\n",
    "                event = event + 1\n",
    "            previousRow = row\n",
    "        except Exception as ex:\n",
    "            continue\n",
    "\n",
    "    return(timeSpeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historyLevelData(deviceList,unit):\n",
    "    historyTempData = pd.DataFrame()\n",
    "    history=pd.DataFrame()\n",
    "    \n",
    "    for imei in deviceList['imei'].unique():\n",
    "        startDate = deviceList.loc[deviceList['imei']==imei, \"begin_time\"].max()\n",
    "        endDate = deviceList.loc[deviceList['imei']==imei, \"end_time\"].max()\n",
    "\n",
    "        try:\n",
    "            \n",
    "            queryHistory = clientBigQueryLocationWorld.query(\"\"\"SELECT *\n",
    "                                    FROM `conf_idelcial_BQ.{}`\n",
    "                                    WHERE generateTime >= '{}' and generateTime <= '{}'\n",
    "                                    order by generateTime\"\"\".format(imei, startDate, endDate))\n",
    "\n",
    "            resultHistory = queryHistory.result()\n",
    "            history = resultHistory.to_dataframe()\n",
    "            history = history[(history['_t']=='OnlineMessage')]\n",
    "            history['imei']=imei\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        if history.shape[0]>0:\n",
    "            dataFrame = pd.merge(history, unit, how='inner', on=['imei'])    \n",
    "            dataFrame = dataFrame.sort_values(by = [\"imei\", \"generateTime\"])\n",
    "            dataFrame[\"generateTime\"] = pd.to_datetime(dataFrame.generateTime).dt.tz_localize(None)\n",
    "            dataFrame[\"generateTime\"] = dataFrame[\"generateTime\"] + timedelta(hours = offset)\n",
    "            dataFrame[\"mileage\"]=dataFrame[\"mileage\"].apply( lambda x: format(x,'.2f')).values.astype(np.float)\n",
    "            dataFrame[\"additionalTripId\"]=dataFrame[\"additionalTripId\"].astype(int)\n",
    "            dataFrame['date'] = dataFrame.generateTime.dt.date\n",
    "            dataFrame['hour'] = dataFrame.generateTime.dt.hour\n",
    "            dataFrame = dataFrame.sort_values(by = [\"imei\",\"generateTime\"],ascending=False)\n",
    "            dataFrame[\"km\"]=dataFrame[\"mileage\"]-dataFrame[\"mileage\"].shift(-1)\n",
    "            dataFrame.driverFullName =dataFrame.driverFullName.fillna('Sin Información')\n",
    "            dataFrame=dataFrame.fillna(0)\n",
    "\n",
    "            dataFrame['test'] = dataFrame.date.astype(str) + dataFrame.hour.astype(str) + dataFrame.groupName.astype(str) + dataFrame.automotor_plate.astype(str) + dataFrame.imei.astype(str) + dataFrame.alias.astype(str) + dataFrame.additionalTripId.astype(str) + dataFrame.driverFullName.astype(str)\n",
    "            dataFrame.test=dataFrame.test.astype(str)\n",
    "            dataFrame=dataFrame.fillna(0)\n",
    "            \n",
    "            final=pd.DataFrame()\n",
    "\n",
    "            for trip in dataFrame.additionalTripId.unique():\n",
    "                temp=dataFrame[dataFrame.additionalTripId==trip]\n",
    "\n",
    "                if temp.shape[0]<2:\n",
    "                    cualquier_valor=2\n",
    "                else:\n",
    "                    groupData = temp.sort_values('generateTime', ascending=True).groupby(['date', 'hour', 'groupName', 'automotor_plate','automotor_chasis', 'imei', 'alias', 'additionalTripId', 'driverFullName'])\n",
    "                    dataInfo = temp.sort_values('generateTime', ascending=True)[['date', 'hour', 'groupName', 'automotor_plate','automotor_chasis', 'imei', 'alias', 'additionalTripId', 'driverFullName','test']].drop_duplicates()\n",
    "                    dataInfo['hour_mileage'] = groupData.km.sum().to_list()\n",
    "                    dataInfo['odometer'] = groupData.mileage.max().to_list()\n",
    "\n",
    "                    final=final.append(dataInfo)\n",
    "\n",
    "            if final.shape[0]>0:\n",
    "\n",
    "                dataFrame=dataFrame[dataFrame.additionalTripId.isin(final.additionalTripId.unique())].sort_values('generateTime')\n",
    "\n",
    "                df_group = pd.DataFrame(dataFrame.sort_values('generateTime', ascending=True).groupby(['test','additionalTripId'])['speed'].sum()).reset_index()\n",
    "\n",
    "\n",
    "                for t in dataFrame.test.unique():\n",
    "                    aux=dataFrame[dataFrame.test==t]\n",
    "                    aux_index=aux.index.values\n",
    "\n",
    "                    # calculos para idle - movement\n",
    "                    timeSpeed_idle=idleTime(aux)\n",
    "                    timeSpeed_move=movementTime(aux)\n",
    "\n",
    "                    aux_final=df_group[df_group.test==t].index.values\n",
    "\n",
    "                    df_group.at[aux_final,'idleTime']=timeSpeed_idle\n",
    "                    df_group.at[aux_final,'movementTime']=timeSpeed_move\n",
    "\n",
    "                df_group=df_group.sort_values('test').reset_index(drop=True)\n",
    "                final=final.sort_values('test').reset_index(drop=True)\n",
    "\n",
    "                final['idleTime']=df_group.idleTime\n",
    "                final['movementTime']=df_group.movementTime\n",
    "\n",
    "    #             final=final.sort_values(by='hour')\n",
    "                stop = (final.groupby(['date', 'hour', 'groupName', 'automotor_plate','automotor_chasis', 'imei', 'alias', 'driverFullName'])['idleTime', 'movementTime'].sum()).reset_index()\n",
    "\n",
    "                stop['stopTime'] = 3600 - (stop.idleTime + stop.movementTime)\n",
    "                stop['additionalTripId']=-1\n",
    "\n",
    "                dataInfo = pd.merge(final, stop[['imei', 'date', 'hour', 'stopTime']], how='left', on=['imei', 'date', 'hour'])\n",
    "                aux = pd.merge(final, stop[['imei', 'date', 'hour', 'stopTime']], how='left', on=['imei', 'date', 'hour']).drop_duplicates(subset=('imei', 'date', 'hour', 'stopTime'),keep='first').reset_index()\n",
    "\n",
    "                stop=stop.sort_values(by=['imei', 'date', 'hour', 'stopTime']).reset_index(drop=True)\n",
    "                dataInfo=dataInfo.sort_values(by=['imei', 'date', 'hour', 'stopTime']).reset_index(drop=True)\n",
    "                aux=aux.sort_values(by=['imei', 'date', 'hour', 'stopTime']).reset_index(drop=True)\n",
    "\n",
    "                final['stopTime']=0\n",
    "\n",
    "                c=0\n",
    "                index_dejar=aux['index'].unique()\n",
    "                for index in index_dejar:\n",
    "                    final.loc[index,'stopTime']=stop.loc[c,'stopTime']\n",
    "                    c=c+1    \n",
    "                historyTempData=historyTempData.append(final)\n",
    "        \n",
    "    return (historyTempData.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funciones de guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripsProductivityUpload(tripsData,businessId):    \n",
    "    tempUpload = (tripsData.groupby(['imei']).generateTime.max()).reset_index().rename(columns={'generateTime':'max_date'})\n",
    "    tempUpload['date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "    tempUpload['type'] = 'channel_trips'\n",
    "    tempUpload['flat'] = 1\n",
    "    tempUpload['client_id'] = businessId\n",
    "    tempUpload['process_name'] = processName\n",
    "    tempUpload['dashboard_type'] = dashboardType\n",
    "    tempUpload.to_sql('looker_data_upload', con=psqlCon, schema='platform' ,if_exists='append', index=False)\n",
    "    return(tripsData)\n",
    "    \n",
    "def dailyProductivityUpload(dailyData,businessId):\n",
    "    tempUpload = (dailyData.groupby(['imei']).generateTime.max()).reset_index().rename(columns={'generateTime':'max_date'})\n",
    "    tempUpload['date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "    tempUpload['type'] = 'channel_daily'\n",
    "    tempUpload['flat'] = 1\n",
    "    tempUpload['client_id'] = businessId\n",
    "    tempUpload['process_name'] = processName\n",
    "    tempUpload['dashboard_type'] = dashboardType\n",
    "    tempUpload.to_sql('looker_data_upload', con=psqlCon, schema='platform' ,if_exists='append', index=False)\n",
    "    return(dailyData)\n",
    "\n",
    "def saveTripsData(businessId,tripsData,tableName,project,credenciales):\n",
    "    tripsSave = pd.read_sql(\"\"\"select imei, max(max_date) as begin_time from plat\"\"\", psqlCon)\n",
    "    tripsSaveData = pd.DataFrame()\n",
    "\n",
    "    for imei in tripsData.imei.unique():\n",
    "        tripDate = tripsSave[tripsSave.imei==imei]\n",
    "        if len(tripDate)!=0:\n",
    "            tripsSaveData = tripsSaveData.append(tripsData[(tripsData.imei==imei) &\n",
    "                                                           (tripsData.generateTime > tripDate.begin_time.max())])\n",
    "       \n",
    "        else : tripsSaveData = tripsSaveData.append(tripsData[(tripsData.imei==imei)])\n",
    "    tripsSaveData.to_gbq(destination_table = \"business_{}.{}\")\n",
    "    return(tripsData)\n",
    "\n",
    "def saveDailyData(businessId,dailyData,tableName,project,credenciales):\n",
    "    dailySave = pd.read_sql(\"\"\"select  \"\"\", psqlCon)\n",
    "\n",
    "    dailySaveData = pd.DataFrame()\n",
    "    \n",
    "    for imei in dailyData.imei.unique():\n",
    "        dailyDate = dailySave[dailySave.imei==imei]\n",
    "        if len(dailyDate)!=0:\n",
    "            dailySaveData = dailySaveData.append(dailyData[(dailyData.imei==imei) &\n",
    "                                                           (dailyData.generateTime > dailyDate.begin_time.max())])\n",
    "\n",
    "        else : dailySaveData = dailySaveData.append(dailyData[(dailyData.imei==imei)])\n",
    "    dailySaveData.to_gbq(destination_table = \"business_{}.{}\")\n",
    "    return(dailyData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funciones propias de productividad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripsTotalProcess(trips1):\n",
    "    #Es necesario tener 4 dias para sacar el promedio de km recorrido por vehiculo.\n",
    "    filteredData=historyTempData.copy()\n",
    "    filteredData.additionalTripId=filteredData.additionalTripId.astype(object)\n",
    "    temp=filteredData[[\"groupName\",\"imei\",\"unitAlias\",\"additionalTripId\",\"brand\", \"model\",\"devicePlate\",'km']].groupby([\"groupName\",\"additionalTripId\",\"imei\",\"unitAlias\",\"brand\", \"model\",\"devicePlate\"]).mean()\n",
    "    temp=temp.reset_index(level=[0,1,2,3,4,5,6]).rename(columns={'km':'km_covered_per_day_by_trip'})\n",
    "    km_covered=temp.loc[:,['imei',\"additionalTripId\",'km_covered_per_day_by_trip']].rename(columns={'additionalTripId':'tripId'})\n",
    "\n",
    "    #Los calculos de aqui en adelante solo considerean el ultimo dia de extraccion.\n",
    "    km_total=pd.DataFrame()\n",
    "    filteredData=analyzeData[[\"groupName\",\"imei\",\"unitAlias\",\"additionalTripId\",\"brand\", \"model\",\"devicePlate\",'mileage']]\n",
    "    for imei  in filteredData.imei.unique():\n",
    "        temp=filteredData[filteredData.imei==imei]\n",
    "        temp['km_total_per_day_by_trip']=temp.mileage.max()-temp.mileage.min()\n",
    "        temp=temp.drop_duplicates(subset=[\"additionalTripId\",'km_total_per_day_by_trip'],keep='last')\n",
    "        km_total=km_total.append(temp)\n",
    "    km_total=km_total.loc[:,['imei',\"additionalTripId\",'km_total_per_day_by_trip']].rename(columns={'additionalTripId':'tripId'})\n",
    "    tripsFinal=trips1.merge(km_total,on=['imei','tripId'],how='left')\n",
    "    tripsFinal=tripsFinal.merge(km_covered,on=['imei','tripId'],how='left')\n",
    "    return tripsFinal\n",
    "\n",
    "def tripsCalculation(startDate):\n",
    "    trips1=hoursTripsProcess(analyzeData,startDate)\n",
    "    tripsF=tripsTotalProcess(trips1)\n",
    "    tripFinal2=startEndTrips()\n",
    "    tripsTotal=tripsF.merge(tripFinal2,on=['imei','tripId'])\n",
    "    \n",
    "    chofer=analyzeData[['imei','unitAlias','group_name','driverFullName']].drop_duplicates().rename(columns={'group_name':'groupName'})\n",
    "    tripsTotal=tripsTotal.merge(chofer,on=['imei','unitAlias','groupName'],how='inner')    \n",
    "    return tripsTotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Connection settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### CONFIDENCIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "parameters = { \"_id\": \"geuv8sncw1yMCKPTy0Ge\",\"businessId\": 89,\"clientIdList\":[],\"userId\": 0,\"timeZone\": -5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env='CONFIDENCIAL#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project=env\n",
    "nameDate='generateTime'\n",
    "tableName='tabla_confidencial_1'\n",
    "\n",
    "dashboardType=\"confidencial_standard\"\n",
    "lookerModel=\"modelo_confidencial\"\n",
    "processName=\"productivity\"\n",
    "\n",
    "minVel = 2\n",
    "businessId   = parameters['businessId']\n",
    "clientListParameter = parameters['clientIdList']\n",
    "offset = int(parameters['timeZone'])\n",
    "\n",
    "print(businessId,offset,lookerModel,dashboardType,processName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Requirements verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientsList = pd.read_sql(\"\"\"select  wk.imei, wk.business_id, client_id\n",
    "                                from [sql_conf_tabl].[dbo].[conf_wa] wk\n",
    "                                inner join [sql_conf_tabl].[dbo].[conf_un] wu\n",
    "                                on wk.imei=wu.imei\n",
    "                                where wk.business_id={} \n",
    "                                and wk.status_id=3 \n",
    "                                order by client_id\"\"\".format(businessId), sqlServerCon)\n",
    "\n",
    "print(clientsList.client_id.nunique(),clientsList.imei.nunique())\n",
    "clientsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tuple(clientListParameter))>0:\n",
    "    clientListF=clientsList[clientsList.client_id.isin(clientListParameter)]\n",
    "    print('cinco primeros vehiculos del cliente:',clientListF.head())\n",
    "    if clientListF.shape[0]==0:\n",
    "        print('los clientID ingresados no existen se procede a tomar todos')\n",
    "        clientListF=clientsList.copy()\n",
    "    print(clientListF.shape)\n",
    "else:\n",
    "    clientListF=clientsList.copy()\n",
    "    \n",
    "    print('se toman todos los cleintes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imeisToAnalyze=pd.DataFrame()\n",
    "\n",
    "for clientId in clientListF.client_id.unique():\n",
    "    print(clientId)\n",
    "    try:\n",
    "        unit = decryptCatalogs(urlConnections,clientId, \"device\")\n",
    "        unit = unit[['imei','client','country', 'automotor_plate','automotor_chasis','alias', 'group_name']]\n",
    "\n",
    "        try:\n",
    "            if unit.shape[0]>0:\n",
    "                activeDevices, numActiveDevices = True, unit.shape[0]\n",
    "                imeis=unit.copy()\n",
    "                imeis['clientId']=clientId\n",
    "                imeisToAnalyze=imeisToAnalyze.append(imeis)\n",
    "        except :\n",
    "            print('clientId no existe en encriptacion')\n",
    "    except :\n",
    "        print('1')\n",
    "\n",
    "print('# clientes',imeisToAnalyze.clientId.nunique(),'y # vehiculos',imeisToAnalyze.imei.nunique())\n",
    "print('nombres clientes :',imeisToAnalyze.client.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processBeginTime = datetime.now()\n",
    "\n",
    "if (activeDevices == True): \n",
    "    for clientId in imeisToAnalyze.clientId.unique():\n",
    "        \n",
    "        daily_infoByImei=pd.DataFrame() \n",
    "        trips_infoByImei=pd.DataFrame()\n",
    "        \n",
    "        tempClient=imeisToAnalyze[imeisToAnalyze.clientId==clientId]\n",
    "        \n",
    "        deviceList = getLastData(tempClient, project,clientId,nameDate,tableName)\n",
    "        print('-------------------------------------------------------------------')\n",
    "        print('tempClient',tempClient.shape,'clientID', clientId,'vehiculos a analizar : ',deviceList.shape)\n",
    "        \n",
    "        for imei in deviceList.imei.unique():\n",
    "\n",
    "            tempDeviceList=deviceList[deviceList.imei==imei] \n",
    "            \n",
    "            tripsTotal = historyLevelData(tempDeviceList,tempClient)\n",
    "\n",
    "            if tripsTotal.shape[0]>0:\n",
    "                \n",
    "                tripsTotal['clientId']=clientId.astype(str)\n",
    "                tripsTotal['clientName']=tempClient.reset_index(drop=True).loc[0,'client']\n",
    "                print(tempClient.reset_index(drop=True).loc[0,'client'])\n",
    "\n",
    "                tripsTotal.rename(columns={'date':'generateTime', 'hour':'hourPerDay', 'additionalTripId':'tripId', 'automotor_plate':'devicePlate','hour_mileage':'hourMileage',\n",
    "                                  'alias':'unitAlias', 'idle_time':'idleTime', 'automotor_chasis': 'automotorChasis'},inplace=True)    \n",
    "                tripsTotal = tripsTotal[tripsTotal.hourMileage>=0]\n",
    "                tripsTotal = tripsTotal[(tripsTotal.idleTime + tripsTotal.movementTime + tripsTotal.stopTime)>0]\n",
    "\n",
    "                tripsTotal = tripsTotal.drop_duplicates()\n",
    "\n",
    "                dailyHourReport = (tripsTotal.groupby(['generateTime', 'hourPerDay','clientId','clientName', 'groupName', 'devicePlate', 'imei',\n",
    "                                   'unitAlias','automotorChasis', 'driverFullName'])[['hourMileage','idleTime', 'stopTime', 'movementTime']].sum()).reset_index()\n",
    "                dailyHourReport['odometer'] = list(tripsTotal.groupby(['generateTime', 'hourPerDay','clientId','clientName', 'groupName', 'devicePlate', 'imei',\n",
    "                                                   'unitAlias', 'automotorChasis','driverFullName']).odometer.max())\n",
    "\n",
    "                # validar que el groupName este en object para el esquema de la tabla\n",
    "                dailyHourReport.groupName=dailyHourReport.groupName.apply(lambda x : 'Sin información' if x == 0 else x)\n",
    "                dailyHourReport.groupName=dailyHourReport.groupName.astype(str)\n",
    "\n",
    "                tripsTotal.groupName=tripsTotal.groupName.apply(lambda x : 'Sin información' if x == 0 else x)\n",
    "                tripsTotal.groupName=tripsTotal.groupName.astype(str)\n",
    "\n",
    "                tripsTotal.hourMileage = tripsTotal.hourMileage.astype('float')\n",
    "                tripsTotal.odometer = tripsTotal.odometer.astype('float')\n",
    "                tripsTotal.idleTime = tripsTotal.idleTime.astype('float')\n",
    "                tripsTotal.stopTime = tripsTotal.stopTime.astype('float')\n",
    "                tripsTotal.movementTime = tripsTotal.movementTime.astype('float')\n",
    "                \n",
    "                tripsTotal.hourPerDay=tripsTotal.hourPerDay.astype(int)\n",
    "                dailyHourReport.hourPerDay=dailyHourReport.hourPerDay.astype(int)\n",
    "\n",
    "                dailyHourReport.hourMileage = dailyHourReport.hourMileage.astype('float')\n",
    "                dailyHourReport.odometer = dailyHourReport.odometer.astype('float')\n",
    "                dailyHourReport.idleTime = dailyHourReport.idleTime.astype('float')\n",
    "                dailyHourReport.stopTime = dailyHourReport.stopTime.astype('float')\n",
    "                dailyHourReport.movementTime = dailyHourReport.movementTime.astype('float')\n",
    "\n",
    "                dailyHourReport[\"generateTime\"] = dailyHourReport[\"generateTime\"].astype('datetime64[ns]') + timedelta(hours = -offset*2)\n",
    "                tripsTotal[\"generateTime\"] = tripsTotal[\"generateTime\"].astype('datetime64[ns]') + timedelta(hours = -offset*2)\n",
    "            \n",
    "                dailyHourReport['generateTime']=dailyHourReport.generateTime.apply(lambda x : datetime(x.year, x.month,x.day))\n",
    "                tripsTotal['generateTime']=tripsTotal.generateTime.apply(lambda x : datetime(x.year, x.month,x.day))\n",
    "\n",
    "                daily_infoByImei=daily_infoByImei.append(dailyHourReport) \n",
    "                trips_infoByImei=trips_infoByImei.append(tripsTotal)\n",
    "\n",
    "            print(imei,tripsTotal.shape,daily_infoByImei.shape,trips_infoByImei.shape,'wow')\n",
    "            print('--------------------')  \n",
    "        \n",
    "        ### SAVE DATA\n",
    "        crdl=bigQueryCredentialsLookerAnalytics\n",
    "        ver='confidencial'\n",
    "        \n",
    "        if (trips_infoByImei.shape[0]>0):\n",
    "            trips_infoByImei=trips_infoByImei.drop(columns='test')\n",
    "            trips_infoByImei.tripId=trips_infoByImei.tripId.astype(int)\n",
    "            tripsData = saveTripsData(businessId, trips_infoByImei, 'modelo_confidencial_daily_trip_hour', ver,crdl)\n",
    "            tripsData = tripsProductivityUpload(tripsData,businessId)\n",
    "\n",
    "        if (daily_infoByImei.shape[0]>0):\n",
    "            dailyData = saveDailyData(businessId, daily_infoByImei, 'tabla_confidencial_1',ver,crdl)\n",
    "            dailyData = dailyProductivityUpload(dailyData,businessId)\n",
    "\n",
    "print(' horas:',daily_infoByImei.shape,'| trips:',trips_infoByImei.shape)\n",
    "#print(datetime.now())\n",
    "processEndTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save execution log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#humidityNullValues, productivityNullValues, productivityOutlier, humidityOutlier, tempMinOutlier, tempMaxOutlier, tempMeanOutlier, humMinOutlier, humMaxOutlier, humMeanOutlier = dataframeExplore(analysisData)\n",
    "#logDataframe = pd.DataFrame({\n",
    "#    'clientId' : clientId,\n",
    "#    'process' : processName,\n",
    "#    'dashboardType' : dashboardType,\n",
    "#    'lookerModel' : lookerModel,\n",
    "#    'startAt' : processBeginTime,\n",
    "#    'endedAt' : processEndTime,\n",
    "#    'rowsGeneratedHistory' : historyTempData.shape[0],\n",
    "#    'rowsGeneratedTrips' : tripsData.shape[0],\n",
    "#    'rowsGeneratedDaily' : dailyData.shape[0],\n",
    "#    'processed_devices' : historyTempData.imei.nunique()\n",
    "#}, index = {1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
